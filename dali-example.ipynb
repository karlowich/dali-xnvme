{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f68b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from nvidia.dali.backend import TensorListGPU\n",
    "from nvidia.dali import pipeline_def, Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ctypes\n",
    "from ctypes import CFUNCTYPE, POINTER, c_int, c_void_p, byref, pointer\n",
    "import xnvme.ctypes_bindings as xnvme\n",
    "from xnvme.ctypes_bindings.api import char_pointer_cast\n",
    "\n",
    "\n",
    "DATADIR = \"/data\"\n",
    "BATCH_SIZE = 4 # batch size per GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buf_and_view(dev, buffer_size):\n",
    "    \"\"\"\n",
    "    Returns a buffer of the given 'buffer_size' along with a numpy-view\n",
    "\n",
    "    The view covers the entire buffer and typed as uint8. The buffer is\n",
    "    zero-filled via the view. Thus, the pages backing the buffer should be\n",
    "    allocated.\n",
    "    \"\"\"\n",
    "\n",
    "    buf = xnvme.xnvme_buf_alloc(dev, buffer_size)\n",
    "\n",
    "    view = np.ctypeslib.as_array(\n",
    "        ctypes.cast(buf, ctypes.POINTER(ctypes.c_uint8)),\n",
    "        shape=(buffer_size,),\n",
    "    )\n",
    "    view[:] = 0  # Zero memory and force page allocation\n",
    "\n",
    "    return buf, view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ecda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/image_processing/decoder_examples.html\n",
    "def show_images(image_batch):\n",
    "    columns = 4\n",
    "    rows = BATCH_SIZE // (columns)\n",
    "    fig = plt.figure(figsize=(32, (32 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows * columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image_batch.at(j))\n",
    "\n",
    "def show_pipeline_output(pipe):\n",
    "    pipe.build()\n",
    "    images, _ = pipe.run()\n",
    "    if isinstance(images, TensorListGPU):\n",
    "        images = images.as_cpu()\n",
    "    show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline_def\n",
    "def ref_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    # We are interested in replacing this call with an external source\n",
    "    jpegs, labels = fn.readers.file(file_root=traindir,\n",
    "            shard_id=0,\n",
    "            num_shards=1,\n",
    "            random_shuffle=True,\n",
    "            pad_last_batch=True,)\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/NVIDIA/DALI/blob/main/docs/examples/frameworks/pytorch/pytorch-external_input.ipynb\n",
    "class FileInputIterator(object):\n",
    "    # This is essentially fn.readers.file reimplemented as an external source\n",
    "    def __init__(self, batch_size, device_id, num_gpus):\n",
    "        self.images_dir = \"/data/train/\"\n",
    "        self.batch_size = batch_size\n",
    "        dirs = {os.path.join(self.images_dir, d): i for i, d in enumerate(sorted(os.listdir(self.images_dir)))}\n",
    "        self.files = [(os.path.join(root, file), dirs[root]) for root, _, files in os.walk(self.images_dir) for file in files]\n",
    "        # whole data set size\n",
    "        self.data_set_len = len(self.files)\n",
    "        # based on the device_id and total number of GPUs - world size\n",
    "        # get proper shard\n",
    "        self.files = self.files[\n",
    "            self.data_set_len\n",
    "            * device_id\n",
    "            // num_gpus : self.data_set_len\n",
    "            * (device_id + 1)\n",
    "            // num_gpus\n",
    "        ]\n",
    "        self.n = len(self.files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        shuffle(self.files)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        labels = []\n",
    "\n",
    "        if self.i >= self.n:\n",
    "            self.__iter__()\n",
    "            raise StopIteration\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            jpeg, label = self.files[self.i % self.n]\n",
    "\n",
    "            batch.append(\n",
    "                np.fromfile(jpeg, dtype=np.uint8)\n",
    "            )\n",
    "            labels.append(\n",
    "                torch.tensor([label], dtype=torch.int32)\n",
    "            )\n",
    "            self.i += 1\n",
    "        return (batch, labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_set_len\n",
    "\n",
    "    next = __next__\n",
    "    \n",
    "@pipeline_def\n",
    "def file_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.external_source(\n",
    "        source=FileInputIterator(BATCH_SIZE, 0, 1), num_outputs=2, dtype=[types.UINT8, types.INT32]\n",
    "    )\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XNVMEFileInputIterator(object):\n",
    "    # This is implemented using the xNVMe file API\n",
    "    def __init__(self, batch_size, device_id, num_gpus):\n",
    "        self.images_dir = \"/data/train/\"\n",
    "        self.batch_size = batch_size\n",
    "        dirs = {os.path.join(self.images_dir, d): i for i, d in enumerate(sorted(os.listdir(self.images_dir)))}\n",
    "        self.files = [(os.path.join(root, file), dirs[root]) for root, _, files in os.walk(self.images_dir) for file in files]\n",
    "        # whole data set size\n",
    "        self.data_set_len = len(self.files)\n",
    "        # based on the device_id and total number of GPUs - world size\n",
    "        # get proper shard\n",
    "        self.files = self.files[\n",
    "            self.data_set_len\n",
    "            * device_id\n",
    "            // num_gpus : self.data_set_len\n",
    "            * (device_id + 1)\n",
    "            // num_gpus\n",
    "        ]\n",
    "        self.n = len(self.files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        shuffle(self.files)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        labels = []\n",
    "\n",
    "        if self.i >= self.n:\n",
    "            self.__iter__()\n",
    "            raise StopIteration\n",
    "        \n",
    "        opts = xnvme.xnvme_opts()\n",
    "        xnvme.xnvme_opts_set_defaults(ctypes.byref(opts))\n",
    "        for _ in range(self.batch_size):\n",
    "            jpeg, label = self.files[self.i % self.n]\n",
    "                \n",
    "            file = xnvme.xnvme_file_open(char_pointer_cast(jpeg), ctypes.byref(opts))\n",
    "            assert file\n",
    "            size = xnvme.xnvme_dev_get_geo(file).contents.tbytes\n",
    "            buf, view = buf_and_view(file, size)\n",
    "            ctx = xnvme.xnvme_file_get_cmd_ctx(file)\n",
    "            err = xnvme.xnvme_file_pread(byref(ctx), buf, size, 0)\n",
    "            assert not err\n",
    "            assert pointer(ctx).contents.cpl.result == size == view.shape[0]\n",
    "            \n",
    "            batch.append(\n",
    "                np.frombuffer(np.copy(view), dtype=np.uint8)\n",
    "            )\n",
    "            \n",
    "            labels.append(\n",
    "                torch.tensor([label], dtype=torch.int32)\n",
    "            )\n",
    "            xnvme.xnvme_buf_free(file, buf)\n",
    "            xnvme.xnvme_file_close(file)\n",
    "            \n",
    "            self.i += 1\n",
    "        \n",
    "        return (batch, labels)\n",
    "\n",
    "    next = __next__\n",
    "    \n",
    "@pipeline_def\n",
    "def xnvme_file_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.external_source(\n",
    "        source=XNVMEFileInputIterator(BATCH_SIZE, 0, 1),\n",
    "        num_outputs=2, dtype=[types.UINT8, types.INT32],\n",
    "    )\n",
    "    breakpoint()\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XNVMEBlockInputIterator(object):\n",
    "    # This will be implemented using the xNVMe API with the filename -> block mapping \n",
    "    def __init__(self, batch_size, device_id, num_gpus):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        pass\n",
    "\n",
    "    def __next__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    next = __next__\n",
    "    \n",
    "@pipeline_def\n",
    "def xnvme_block_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.external_source(\n",
    "        source=XNVMEBlockInputIterator(BATCH_SIZE, 0, 1), num_outputs=2, dtype=[types.UINT8, types.INT32]\n",
    "    )\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reference using DALI fn.readers.file\n",
    "ref_pipe = ref_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "ref_start = time.time()\n",
    "show_pipeline_output(ref_pipe)\n",
    "ref_end = time.time()\n",
    "\n",
    "\n",
    "# Replacing with fn.readers.file with external source\n",
    "file_pipe = file_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "file_start = time.time()\n",
    "show_pipeline_output(file_pipe)\n",
    "file_end = time.time()\n",
    "\n",
    "\n",
    "# Using xNVMe file with the external source\n",
    "xnvme_file_pipe = xnvme_file_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "xnvme_file_start = time.time()\n",
    "show_pipeline_output(xnvme_file_pipe)\n",
    "xnvme_file_end = time.time()\n",
    "\n",
    "print(\"Reference:\", ref_end - ref_start)\n",
    "print(\"File:\", file_end - file_start)\n",
    "print(\"xNVMe File:\", xnvme_file_end - xnvme_file_start)\n",
    "\n",
    "\n",
    "# Using xNVMe block with the mapping layer\n",
    "# xnvme_block_pipe = xnvme_block_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "# show_pipeline_output(xnvme_block_pipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
