{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator\n",
    "from nvidia.dali.backend import TensorListGPU\n",
    "from nvidia.dali import pipeline_def, Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATADIR = \"/data\"\n",
    "BATCH_SIZE = 4 # batch size per GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579160b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/image_processing/decoder_examples.html\n",
    "def show_images(image_batch):\n",
    "    columns = 4\n",
    "    rows = (BATCH_SIZE + 1) // (columns)\n",
    "    fig = plt.figure(figsize=(32, (32 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows * columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image_batch.at(j))\n",
    "\n",
    "def show_pipeline_output(pipe):\n",
    "    pipe.build()\n",
    "    images, _ = pipe.run()\n",
    "    if isinstance(images, TensorListGPU):\n",
    "        images = images.as_cpu()\n",
    "    show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline_def\n",
    "def int_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.readers.file(file_root=traindir,\n",
    "            shard_id=0,\n",
    "            num_shards=1,\n",
    "            random_shuffle=True,\n",
    "            pad_last_batch=True,)\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    images = fn.random_resized_crop(\n",
    "        images,\n",
    "        device=\"gpu\",\n",
    "        size=[crop, crop],\n",
    "        interp_type=types.INTERP_LINEAR,\n",
    "        random_aspect_ratio=[0.75, 4.0 / 3.0],\n",
    "        random_area=[0.08, 1.0],\n",
    "        num_attempts=100,\n",
    "        antialias=False,\n",
    "    )\n",
    "    images = fn.crop_mirror_normalize(\n",
    "        images,\n",
    "        device=\"gpu\",\n",
    "        dtype=types.FLOAT,\n",
    "#         output_layout=types.NCHW,\n",
    "        output_layout=\"HWC\",\n",
    "        crop=(crop, crop),\n",
    "        mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "        std=[0.229 * 255, 0.224 * 255, 0.225 * 255],\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExternalInputIterator(object):\n",
    "    def __init__(self, batch_size, device_id, num_gpus):\n",
    "        self.images_dir = \"/data/train/\"\n",
    "        self.batch_size = batch_size\n",
    "        dirs = {os.path.join(self.images_dir, d): i for i, d in enumerate(sorted(os.listdir(self.images_dir)))}\n",
    "        self.files = [(os.path.join(root, file), dirs[root]) for root, _, files in os.walk(self.images_dir) for file in files]\n",
    "        # whole data set size\n",
    "        self.data_set_len = len(self.files)\n",
    "        # based on the device_id and total number of GPUs - world size\n",
    "        # get proper shard\n",
    "        self.files = self.files[\n",
    "            self.data_set_len\n",
    "            * device_id\n",
    "            // num_gpus : self.data_set_len\n",
    "            * (device_id + 1)\n",
    "            // num_gpus\n",
    "        ]\n",
    "        self.n = len(self.files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        shuffle(self.files)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        labels = []\n",
    "\n",
    "        if self.i >= self.n:\n",
    "            self.__iter__()\n",
    "            raise StopIteration\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            jpeg, label = self.files[self.i % self.n]\n",
    "            batch.append(\n",
    "                np.fromfile(jpeg, dtype=np.uint8)\n",
    "            )  # we can use numpy\n",
    "            labels.append(\n",
    "                torch.tensor([label], dtype=torch.int32)\n",
    "            )  # or PyTorch's native tensors\n",
    "            self.i += 1\n",
    "        return (batch, labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_set_len\n",
    "\n",
    "    next = __next__\n",
    "    \n",
    "@pipeline_def\n",
    "def ext_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.external_source(\n",
    "        source=ExternalInputIterator(BATCH_SIZE, 0, 1), num_outputs=2, dtype=[types.UINT8, types.INT32]\n",
    "    )\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    images = fn.random_resized_crop(\n",
    "        images,\n",
    "        device=\"gpu\",\n",
    "        size=[crop, crop],\n",
    "        interp_type=types.INTERP_LINEAR,\n",
    "        random_aspect_ratio=[0.75, 4.0 / 3.0],\n",
    "        random_area=[0.08, 1.0],\n",
    "        num_attempts=100,\n",
    "        antialias=False,\n",
    "    )\n",
    "    images = fn.crop_mirror_normalize(\n",
    "        images,\n",
    "        device=\"gpu\",\n",
    "        dtype=types.FLOAT,\n",
    "#         output_layout=types.NCHW,\n",
    "        output_layout=\"HWC\",\n",
    "        crop=(crop, crop),\n",
    "        mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "        std=[0.229 * 255, 0.224 * 255, 0.225 * 255],\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pipe = int_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "show_pipeline_output(int_pipe)\n",
    "\n",
    "ext_pipe = ext_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "show_pipeline_output(ext_pipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
