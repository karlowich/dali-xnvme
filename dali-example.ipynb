{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b52f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from nvidia.dali.backend import TensorListGPU\n",
    "from nvidia.dali import pipeline_def, Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATADIR = \"/data\"\n",
    "BATCH_SIZE = 4 # batch size per GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/image_processing/decoder_examples.html\n",
    "def show_images(image_batch):\n",
    "    columns = 4\n",
    "    rows = (BATCH_SIZE + 1) // (columns)\n",
    "    fig = plt.figure(figsize=(32, (32 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows * columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image_batch.at(j))\n",
    "\n",
    "def show_pipeline_output(pipe):\n",
    "    pipe.build()\n",
    "    images, _ = pipe.run()\n",
    "    if isinstance(images, TensorListGPU):\n",
    "        images = images.as_cpu()\n",
    "    show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b36a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline_def\n",
    "def ref_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    # We are interested in replacing this call with an external source\n",
    "    jpegs, labels = fn.readers.file(file_root=traindir,\n",
    "            shard_id=0,\n",
    "            num_shards=1,\n",
    "            random_shuffle=True,\n",
    "            pad_last_batch=True,)\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/NVIDIA/DALI/blob/main/docs/examples/frameworks/pytorch/pytorch-external_input.ipynb\n",
    "class FileInputIterator(object):\n",
    "    # This is essentially fn.readers.file reimplemented as an external source\n",
    "    def __init__(self, batch_size, device_id, num_gpus):\n",
    "        self.images_dir = \"/data/train/\"\n",
    "        self.batch_size = batch_size\n",
    "        dirs = {os.path.join(self.images_dir, d): i for i, d in enumerate(sorted(os.listdir(self.images_dir)))}\n",
    "        self.files = [(os.path.join(root, file), dirs[root]) for root, _, files in os.walk(self.images_dir) for file in files]\n",
    "        # whole data set size\n",
    "        self.data_set_len = len(self.files)\n",
    "        # based on the device_id and total number of GPUs - world size\n",
    "        # get proper shard\n",
    "        self.files = self.files[\n",
    "            self.data_set_len\n",
    "            * device_id\n",
    "            // num_gpus : self.data_set_len\n",
    "            * (device_id + 1)\n",
    "            // num_gpus\n",
    "        ]\n",
    "        self.n = len(self.files)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        shuffle(self.files)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        labels = []\n",
    "\n",
    "        if self.i >= self.n:\n",
    "            self.__iter__()\n",
    "            raise StopIteration\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            jpeg, label = self.files[self.i % self.n]\n",
    "            batch.append(\n",
    "                np.fromfile(jpeg, dtype=np.uint8)\n",
    "            )\n",
    "            labels.append(\n",
    "                torch.tensor([label], dtype=torch.int32)\n",
    "            )\n",
    "            self.i += 1\n",
    "        return (batch, labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_set_len\n",
    "\n",
    "    next = __next__\n",
    "    \n",
    "@pipeline_def\n",
    "def file_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.external_source(\n",
    "        source=FileInputIterator(BATCH_SIZE, 0, 1), num_outputs=2, dtype=[types.UINT8, types.INT32]\n",
    "    )\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a670a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XNVMEFileInputIterator(object):\n",
    "    # This will be implemented using the xNVMe file API \n",
    "    def __init__(self, batch_size, device_id, num_gpus):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        pass\n",
    "\n",
    "    def __next__(self):\n",
    "        # TODO: Open buffer with xNVMe file and pass it to\n",
    "        # torch.frombuffer(buf, dtype=torch.uint8)\n",
    "        pass\n",
    "            \n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    next = __next__\n",
    "    \n",
    "@pipeline_def\n",
    "def xnvme_file_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.external_source(\n",
    "        source=XNVMEFileInputIterator(BATCH_SIZE, 0, 1), num_outputs=2, dtype=[types.UINT8, types.INT32]\n",
    "    )\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f240741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XNVMEBlockInputIterator(object):\n",
    "    # This will be implemented using the xNVMe API with the filename -> block mapping \n",
    "    def __init__(self, batch_size, device_id, num_gpus):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        pass\n",
    "\n",
    "    def __next__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    next = __next__\n",
    "    \n",
    "@pipeline_def\n",
    "def xnvme_block_pipeline(crop=224):\n",
    "    traindir = os.path.join(DATADIR, \"train\")\n",
    "    jpegs, labels = fn.external_source(\n",
    "        source=XNVMEBlockInputIterator(BATCH_SIZE, 0, 1), num_outputs=2, dtype=[types.UINT8, types.INT32]\n",
    "    )\n",
    "    images = fn.decoders.image(jpegs,\n",
    "        device=\"mixed\",\n",
    "        output_type=types.RGB,\n",
    "        device_memory_padding=211025920,\n",
    "        host_memory_padding=140544512,\n",
    "    )\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2459d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reference using DALI fn.readers.file\n",
    "ref_pipe = ref_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "show_pipeline_output(ref_pipe)\n",
    "\n",
    "# Replacing with fn.readers.file with external source\n",
    "file_pipe = file_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "show_pipeline_output(file_pipe)\n",
    "\n",
    "# Using xNVMe file with the external source\n",
    "# xnvme_file_pipe = xnvme_file_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "# show_pipeline_out(xnvme_file_pipe)\n",
    "\n",
    "# Using xNVMe block with the mapping layer\n",
    "# xnvme_block_pipe = xnvme_block_pipeline(batch_size=BATCH_SIZE, num_threads=2, device_id=0)\n",
    "# show_pipeline_out(xnvme_block_pipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
